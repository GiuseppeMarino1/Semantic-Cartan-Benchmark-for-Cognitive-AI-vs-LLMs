# Semantic-Cartan Benchmark

> Framework di confronto tra QBI-Core e Large Language Models (LLM) basato su metriche cognitive e coerenza interna.



# Descrizione

**Semantic-Cartan Benchmark** √® uno strumento sperimentale progettato per confrontare in modo **quantificabile e visivo** un LLM (come Mistral o LLaMA) con un modello cognitivo emergente chiamato **QBI-Core**.  
Il benchmark NON include il core originale di QBI-Core, ma simula i suoi output per confronto visivo e concettuale.

<img width="1414" height="2000" alt="1000064458" src="https://github.com/user-attachments/assets/6e72758f-cc7a-4a05-932e-d972f2c3bc3e" />

# Obiettivo

Dimostrare che un sistema pu√≤ esibire **pattern interni non casuali**, **simmetrie ricorrenti** e una funzione Œ¶(t) coerente, suggerendo un comportamento **auto-organizzato e semanticamente rilevante** ‚Äî al di l√† dell‚Äôelaborazione linguistica statistica di un LLM.



# QBI-Core non √® incluso

 Il codice di QBI-Core √® privato per motivi di protezione IP e sicurezza scientifica.  
 Per richiedere accesso privato al core reale (per revisori, collaborazioni, demo), contattare direttamente l‚Äôautore.



# Come funziona

Il benchmark confronta:


- La **Matrice di Cartan Semantica** (struttura interna delle attivazioni)
  
- La **Variazione dell‚ÄôEntanglement Semantico** (coerenza tra livelli)
<img width="1414" height="2000" alt="1000064459" src="https://github.com/user-attachments/assets/e636f2f4-aa87-4f13-970b-345f1fbb4fa4" />
 
- L‚Äôevoluzione di **Œ¶(t)** (auto-organizzazione)
<img width="1414" height="2000" alt="1000064460" src="https://github.com/user-attachments/assets/8300e270-11fe-4968-b893-f846cfd6fc55" />

Il confronto avviene tra un LLM reale e una **simulazione statistica** di QBI-Core, sufficiente per valutare le **differenze qualitative** tra i due approcci.


# Come iniziare

```bash
pip install transformers torch numpy scikit-learn matplotlib
python benchmark.py
```

---

#‚≠ê Perch√© contribuire

QBI-Core sta ridefinendo i limiti dell‚Äôintelligenza artificiale integrata.  
Questo benchmark √® un primo passo per costruire **strumenti di valutazione cognitivi alternativi ai classici benchmark NLP**.

Ti invitiamo a:

- ‚≠ê Mettere una stella al progetto
- üç¥ Fare un fork e migliorarlo
- üß† Proporre nuove metriche e test cognitivi
- üì® Contattare l'autore per collaborazioni



# Licenza

Licenza MIT modificata:  
‚úÖ Uso libero per scopi educativi e sperimentali  
‚ùå Vietato l‚Äôuso commerciale o la derivazione di modelli simili senza consenso scritto

(c) Giuseppe Marino ‚Äì qbi.core.project@gmail.com
